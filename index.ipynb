{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient of Determination - Lab\n",
    "\n",
    "## Introduction\n",
    "In the previous lesson, we looked at the Coefficient of Determination, what it means and how it is calculated. In this lesson, we shall use the R-Squared formula to calculate it in python and numpy. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Mathematically calculate R-Squared using a toy dataset\n",
    "\n",
    "* Calculate the coefficient of determination (R-Squared) for a given regression line\n",
    "\n",
    "* Interpret the value of R-Squared\n",
    "\n",
    "\n",
    "## Let's get started\n",
    "\n",
    "Once a regression model is created, we need to decide how \"accurate\" the regression line is to some degree. \n",
    "\n",
    "\n",
    "Here is the equation for R-Squared or the Coefficient of Determination again: \n",
    "\n",
    "$$ R^2 = 1- \\dfrac{SS_{RES}}{SS_{TOT}} = \\dfrac{\\sum_i(y_i - \\hat y_i)^2}{\\sum_i(y_i - \\overline y_i)^2} $$\n",
    " \n",
    " Note that this is also equal to:\n",
    "\n",
    "$$ R^2 = 1- \\dfrac{SS_{RES}}{SS_{TOT}}=\\dfrac{SS_{EXP}}{SS_{TOT}} $$\n",
    "where\n",
    "\n",
    "- $SS_{TOT} = \\sum_i(y_i - \\overline y_i)^2$ $\\rightarrow$ Total Sum of Squares  \n",
    "-  $SS_{EXP} = \\sum_i(\\hat y_i - \\overline y_i)^2$ $\\rightarrow$  Explained Sum of Squares\n",
    "- $SS_{RES}= \\sum_i(y_i - \\hat y_i)^2 $ $\\rightarrow$ Residual Sum of Squares\n",
    "\n",
    "Recall that the objective of $R^2$ is to learn how much of the error is a result in variation in the data features, as opposed to being a result of the regression line being a poor fit.\n",
    "\n",
    "## Programming R-Squared\n",
    "\n",
    "Let's calculate R-Squared in Python. The first step would be to calculate the Squared Error. Remember that the Squared Error is the Residual Sum of Squares of the difference between a given line and the actual data points.\n",
    "\n",
    "Create a function `sq_err()` that takes in y points for 2 arrays, calculates the difference corresponding elements of these arrays, squares, and sums all the differences. The function should return the RSS value you saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'leny_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b91e751a4aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mY_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msq_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b91e751a4aa8>\u001b[0m in \u001b[0;36msq_err\u001b[0;34m(y_a, y_b)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mymean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleny_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'leny_a' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate sum of squared errors between regression and mean line \n",
    "import numpy as np\n",
    "\n",
    "def sq_err(y_a, y_b):\n",
    "    ymean = sum(y_a)/len(y_a)\n",
    "    top = sum([(y_a[n]-y_b[n])**2 for n in range(0,len(y_a))])\n",
    "    bottom = sum([(y_a[n]-(ymean))**2 for n in range (0,len(y_a)])\n",
    "    return top/bottom\n",
    "\n",
    "\n",
    "# Check the output with some toy data\n",
    "Y_a = np.array([1,3,5,7])\n",
    "Y_b = np.array([1,4,5,8])\n",
    "\n",
    "sq_err(Y_a, Y_b)\n",
    "\n",
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squared error, as calculated above is only a part of the coefficient of determination, Let's now build a function that uses `sq_err()` function above to calculate the value of R-Squared by first calculating SSE, then use this same function to calculate SST (use the mean of $y$ instead of the regression line), and then plug in these values into the R-Squared formula. Perform the following tasks\n",
    "* Calculate the mean of the `y_real`\n",
    "* Calculate SSE using `sq_err()`\n",
    "* Calculate SST using `sq_err()`\n",
    "* Calculate R-Squared from above values using the given formula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Y_mean , squared error for regression and mean line , and calculate r-squared\n",
    "\n",
    "def r_squared(y_real, y_predicted):\n",
    "    \"\"\"\n",
    "    input\n",
    "    y_real: real values\n",
    "    y_predicted: regression values\n",
    "    \n",
    "    return\n",
    "    r_squared value\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Check the output with some toy data\n",
    "Y = np.array([1,3,5,7])\n",
    "Y_pred = np.array([1,5,5,10])\n",
    "\n",
    "r_squared(Y, Y_pred)\n",
    "\n",
    "# 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This R-Squared value is very low, but remember that it wasn't from real data. So now, we have quite a few functions for calculating slope, intercept, best-fit line, plotting and calculating R-squared. In the next lab, you'll put these all together to run a complete regression experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this lesson, you learned how to calculate the R-Squared value in python and numpy. In the next lab, you will put all the functions from the last few labs together to create a complete DIY regression experiment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
